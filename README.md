# hw03 - CIS4340 - iv126836

1. Which scraper was selected: I selected Beautiful Soup as I had more experience with it from previous assignments and classes. It was easier to use for this project given the experience I had with it. I had to pip install beautiful soup, then implement with HTML scraping as per the assignment. This allowed me to parse the HTML and create the needed dataframe which was turned into a txt file. 

2. Prompts used to extract the data: Data was extracted using ScrapeGraphAI by using various prompts and codes to get the output needed. Natural language processing is usd by ScrapeGraphAI to understand which graphs to pull and the commands to be completed. The api key was used to connect python prompts to the Ai.

3. A short discussion of the strategy employed in building those prompts: The strategy was to follow the original python code I had to create similar prompts, but using ScrapeGraphAI. The HTML format of the website needed to be considered in the use of ScrapeGraphAI.

4. A summary of the Python development tools employed. To wit, VScode, Jupyter, etc: I used Jupyter to write the code and run it. This created the txt file within Jupyter as well. The python code was transfered to VsCode to be saved as a .py file since Jupyter is saved as a .ipynb.

5. A summary of the plan for developing the functions and a review of any difficulties or hurdles in completing the code: The most difficulty I had was figuring out how to use HTML scraping for the table that had multiple rows within one. This is something I havent worked with previously and wanted to find the most optimal way to scrape the table using python without losing any of the available data. Learning to use ScrapeAI was another hurdle to figure out how to use as it is not something I have used previously.
